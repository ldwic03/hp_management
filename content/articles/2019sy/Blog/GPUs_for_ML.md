Title: 機械学習のための最新GPU比較
Date: 2019.10.07
Modified: 2019.10.07
Tags: Machine Learning
Slug: GPUs_for_ML
Author: 小川
Summary: 某所でGPU調達の必要があって、いまどきの事情を調べました。ゲームのことは知りません。

某所でGPU調達の必要があって、いまどきの事情を調べました。
ゲームのことは知りません。

## 主要GPU一覧

NVidia製Volta/Turing世代ハイエンドデスクトップ／ワークステーション用の主要GPUラインアップ。

|                        | コア            | VRAM     | 最大精度   | TDP      | 放熱     | 価格(税込)    |
| ---------------------- | -------------- | -------- | --------- | -------- | ------- | ------------ |
| GeForce RTX 2080Ti     | Turing (TU102) | *11GB*   | 単精度     | **250W** | 外排気   | 14万円〜      |
| Titan RTX              | Turing (TU102) | 24GB     | 単精度     | *280W*   | *内排気* | 27.6万円〜※   |
| Quadro RTX 6000        | Turing (TU102) | 24GB     | **倍精度** | 260W     | 外排気   | *41.5万円〜*※ |
| Quadro RTX 8000        | Turing (TU102) | **48GB** | **倍精度** | 260W     | 外排気   | 60万円〜※     |
| Titan V                | Volta (V102?)  | *12GB*   | **倍精度** | **250W** | 外排気   | *40万円〜*    |
| Tesla V100 32GB (参考) | Volta (V100)   | 32GB     | **倍精度** | **250W** | 外排気   | *99万円〜*※   |

（**すごい**。*いまいち*。※はアカデミック価格。価格は2019年10月初頭調べ。）

## ポイント

- 目を引くのはTuring世代ワークステーション用GPUの**VRAM大容量化**。
- Titan RTXでも24GB、Quadro RTX 8000に至っては**泣く子も黙る48GB**。
サーバ用のTesla V100も凌ぐ。
- Titan RTXのみ内排気のため、多数枚の搭載には水冷システムが必要。
- Quadro 6000がやや割高なことを除けば、Turingコア製品の**VRAM容量あたりの価格は概ね一定**なのが面白い。
- 大きなネットワークを学習したい時など、GPU1基のメモリ容量はしばしば演算性能以上に重要。
例えばGPU予算が60万の場合、2080Tiを4枚かTitan RTXを2枚かQuadro 8000を1枚か、は用途次第。
- どれもTensorCore搭載。
FP16を使うように調整してやらないと本来の性能は出ない。
- 倍精度演算機能は、実際のところ物理シミュレーションでもしない限り、あっても使わないので関係ない。遅いし。 

## まとめ

演算性能を妥協すれば、大容量VRAMの上位GPUにも実は手が出しやすくなっています。
用途に合わせて選びましょう。
選べる余地があるのはいいことですね。

おしまい。
